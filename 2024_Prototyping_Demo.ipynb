{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+irX8iSUW/T41hHvMluC9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Topics: Prototyping\n",
        "* Gradio\n",
        "* Deploying a Gradio app to Hugging Face\n",
        "* Using a Gradio API from a Node.js application\n",
        "* Streamlit"
      ],
      "metadata": {
        "id": "ZlKi6MU3IJ_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1: Gradio"
      ],
      "metadata": {
        "id": "s7chDwIn7Gxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple gradio example"
      ],
      "metadata": {
        "id": "Fu6Et5nQom2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet gradio"
      ],
      "metadata": {
        "id": "_WNwutaJxwhX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!!\"\n",
        "\n",
        "iface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    iface.launch()"
      ],
      "metadata": {
        "id": "7h4_2vyrxjc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "47829286-2b28-424c-fea9-5798f53c4b60"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8ebefef551bf54d672.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8ebefef551bf54d672.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From spacy to gradio"
      ],
      "metadata": {
        "id": "aOAJMjd3_k2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import gradio as gr\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\") # You need to execute python -m spacy download en_core_web_sm, to be able to use this module\n",
        "\n",
        "# Code adapted from https://journal.code4lib.org/articles/15405\n",
        "def ner(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    places = [ent for ent in doc.ents if ent.label_ in ['GPE', 'LOC']]\n",
        "\n",
        "    return places\n",
        "\n",
        "demo = gr.Interface(fn=ner, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "mEYLa3r-_n_d",
        "outputId": "dba3ab01-bd35-430a-f9ca-ec651489a21a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://832b5bb40011b48289.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://832b5bb40011b48289.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From LLM to gradio"
      ],
      "metadata": {
        "id": "g6fwjUQGopAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uopCM91Vjx4b",
        "outputId": "971e04c2-c5bc-49c7-cabb-cbc7a8a5e7a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/50.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/408.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljSUD_sVj7AI",
        "outputId": "7f2909e3-0d47-4d5b-d630-e4bca8b7bc4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: 路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# From wikipedia: https://en.wikipedia.org/wiki/M%C3%BCnster\n",
        "example_text = \"\"\"\n",
        "M眉nster is an independent city (Kreisfreie Stadt)\n",
        "in North Rhine-Westphalia, Germany. It is in the northern part of the state and is considered to\n",
        " be the cultural centre of the Westphalia region. It is also a state district capital. M眉nster was the\n",
        "  location of the Anabaptist rebellion during the Protestant Reformation and the site of the signing of the\n",
        "   Treaty of Westphalia ending the Thirty Years' War in 1648. Today, it is known as the bicycle capital of Germany.\n",
        "M眉nster gained the status of a Grostadt (major city) with more than 100,000 inhabitants in 1915.[4]\n",
        " As of 2014, there are 300,000[5] people living in the city, with about 61,500 students,[6]\n",
        " only some of whom are recorded in the official population statistics as having their primary residence in M眉nster.\n",
        " M眉nster is a part of the international Euregio region with more than 1,000,000 inhabitants (Enschede, Hengelo, Gronau, Osnabr眉ck). Companies offering jobs in\n",
        " M眉nster include the Institute for Geoinformatics at the University of M眉nster, the M眉nster University of Applied Sciences, Reedu GmbH, con terra,\n",
        " the Deutsche Bank, IKEA, LIDL, REWE, ALDI and BASF Coatings.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "r6zZ6FgFkVGQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Annotated, TypedDict\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
        "\n",
        "# https://python.langchain.com/docs/how_to/structured_output/#typeddict-or-json-schema\n",
        "class NamedEntity(TypedDict):\n",
        "    \"\"\"Entities to retrieve from the passage.\"\"\"\n",
        "\n",
        "    loc: Annotated[str, ..., \"All locations in the passage\"]\n",
        "    event: Annotated[str, ..., \"All events in the passage\"]\n",
        "    org: Annotated[str, ..., \"All organizations in the passage\"]\n",
        "\n",
        "structured_llm = llm.with_structured_output(NamedEntity)\n",
        "\n",
        "structured_llm.invoke(example_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GcRIAgEjvMZ",
        "outputId": "358c6897-4f68-45b9-bba6-6ef1280e24b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loc': 'M眉nster, North Rhine-Westphalia, Germany',\n",
              " 'event': \"Anabaptist rebellion, signing of the Treaty of Westphalia, Thirty Years' War\",\n",
              " 'org': 'Institute for Geoinformatics, University of M眉nster, M眉nster University of Applied Sciences, Reedu GmbH, con terra, Deutsche Bank, IKEA, LIDL, REWE, ALDI, BASF Coatings'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ner_extractor(input_text):\n",
        "  from typing_extensions import Annotated, TypedDict\n",
        "  from langchain_openai import ChatOpenAI\n",
        "\n",
        "  llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
        "\n",
        "  # https://python.langchain.com/docs/how_to/structured_output/#typeddict-or-json-schema\n",
        "  class NamedEntity(TypedDict):\n",
        "      \"\"\"Entities to retrieve from the passage.\"\"\"\n",
        "\n",
        "      loc: Annotated[str, ..., \"All locations in the passage\"]\n",
        "      event: Annotated[str, ..., \"All events in the passage\"]\n",
        "      org: Annotated[str, ..., \"All organizations in the passage\"]\n",
        "\n",
        "  structured_llm = llm.with_structured_output(NamedEntity)\n",
        "\n",
        "  return structured_llm.invoke(example_text)"
      ],
      "metadata": {
        "id": "DhqBQsJEnYt5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "iface = gr.Interface(fn=ner_extractor, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "8yBwDRKhowkf",
        "outputId": "5e1006bd-dece-44c5-a8d1-b9f64d86e82a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://81369a94c954f9b5ba.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://81369a94c954f9b5ba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2: Deploying a Gradio app to Hugging Face\n",
        "\n",
        "* [Example](https://huggingface.co/spaces/aurioldegbelo/ner_space_2023)\n",
        "* [GitHub repository](https://github.com/aurioldegbelo/gradio-demo)\n"
      ],
      "metadata": {
        "id": "Tn1cVXOCGVZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3: Using a Gradio API from a node.js application\n",
        "\n",
        "*   [GitHub repository](https://github.com/aurioldegbelo/gradio-node)\n",
        "\n"
      ],
      "metadata": {
        "id": "FLs3wXezGq4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4: Streamlit\n",
        "* [GitHub repository](https://github.com/aurioldegbelo/graphQA-playground)"
      ],
      "metadata": {
        "id": "K_ujfJUjHcBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project work\n",
        "\n",
        "It's now your turn. Pick a strategy О that fits your skills/interests and start coding !"
      ],
      "metadata": {
        "id": "G5EMvw61HgjO"
      }
    }
  ]
}